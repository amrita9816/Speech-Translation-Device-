{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import model_from_json,load_model,Model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38696, 2)\n"
     ]
    }
   ],
   "source": [
    "lines=pd.read_table('eng-mar-dataset.txt',names=['eng', 'mar','waste'])\n",
    "del lines['waste']\n",
    "print(lines.shape)\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.mar=lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar = lines.mar.apply(lambda x : 'START_ '+ x + ' _END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29597</th>\n",
       "      <td>tom forgot to turn off the gas</td>\n",
       "      <td>START_ टॉम गॅस बंद करायला विसरला _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>dont lose your purse</td>\n",
       "      <td>START_ तुझी पर्स हरवू नकोस _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32160</th>\n",
       "      <td>tom said that he was in australia</td>\n",
       "      <td>START_ टॉम म्हणाला की तो ऑस्ट्रेलियात होता _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32265</th>\n",
       "      <td>where did we get that information</td>\n",
       "      <td>START_ ती माहिती आपल्याला कुठून मिळाली _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28199</th>\n",
       "      <td>it is no use arguing with him</td>\n",
       "      <td>START_ त्याच्याशी भांडण्यात काही अर्थ नाही _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34944</th>\n",
       "      <td>i will go to the doctor this afternoon</td>\n",
       "      <td>START_ मी आज दुपारी डॉक्टरकडे जाईन _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34376</th>\n",
       "      <td>i know him but i dont know his name</td>\n",
       "      <td>START_ मी त्याला ओळखते पण मला त्याचं नाव माहीत...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35538</th>\n",
       "      <td>there are many galaxies in the universe</td>\n",
       "      <td>START_ ब्रह्मांडात अनेक तारामंडळी आहेत _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>i dont travel very much</td>\n",
       "      <td>START_ मी जास्त प्रवास करत नाही _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23096</th>\n",
       "      <td>we were about to call you</td>\n",
       "      <td>START_ आम्ही तुला बोलावणारच होतो _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           eng  \\\n",
       "29597           tom forgot to turn off the gas   \n",
       "14702                     dont lose your purse   \n",
       "32160        tom said that he was in australia   \n",
       "32265        where did we get that information   \n",
       "28199            it is no use arguing with him   \n",
       "34944   i will go to the doctor this afternoon   \n",
       "34376      i know him but i dont know his name   \n",
       "35538  there are many galaxies in the universe   \n",
       "20465                  i dont travel very much   \n",
       "23096                we were about to call you   \n",
       "\n",
       "                                                     mar  \n",
       "29597              START_ टॉम गॅस बंद करायला विसरला _END  \n",
       "14702                    START_ तुझी पर्स हरवू नकोस _END  \n",
       "32160    START_ टॉम म्हणाला की तो ऑस्ट्रेलियात होता _END  \n",
       "32265        START_ ती माहिती आपल्याला कुठून मिळाली _END  \n",
       "28199    START_ त्याच्याशी भांडण्यात काही अर्थ नाही _END  \n",
       "34944            START_ मी आज दुपारी डॉक्टरकडे जाईन _END  \n",
       "34376  START_ मी त्याला ओळखते पण मला त्याचं नाव माहीत...  \n",
       "35538        START_ ब्रह्मांडात अनेक तारामंडळी आहेत _END  \n",
       "20465               START_ मी जास्त प्रवास करत नाही _END  \n",
       "23096              START_ आम्ही तुला बोलावणारच होतो _END  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5585, 13386)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "\n",
    "all_marathi_words=set()\n",
    "for mar in lines.mar:\n",
    "    for word in mar.split():\n",
    "        if word not in all_marathi_words:\n",
    "            all_marathi_words.add(word)\n",
    "            \n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "max_length_src\n",
    "\n",
    "lenght_list=[]\n",
    "for l in lines.mar:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "max_length_tar\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_marathi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_marathi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13387"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_2.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json)\n",
    "\n",
    "model_loaded.load_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "\n",
    "encoder_inputs_inf = model_loaded.input[0] \n",
    "encoder_outputs_inf, inf_state_h, inf_state_c = model_loaded.layers[4].output\n",
    "encoder_inf_states = [inf_state_h,inf_state_c]\n",
    "encoder_model = Model(encoder_inputs_inf,encoder_inf_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_h_input = Input(shape=(latent_dim,)) \n",
    "decoder_state_c_input = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_h_input,decoder_state_c_input]\n",
    "\n",
    "\n",
    "decoder_input_inf = model_loaded.input[1] \n",
    "\n",
    "decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "decoder_lstm_inf = model_loaded.layers[5]\n",
    "decoder_output_inf, decoder_state_h_inf, decoder_state_c_inf = decoder_lstm_inf(decoder_emb_inf, initial_state =decoder_state_input)\n",
    "decoder_state_inf = [decoder_state_h_inf,decoder_state_c_inf]\n",
    "\n",
    "dense_inf = model_loaded.layers[6]\n",
    "decoder_output_final = dense_inf(decoder_output_inf)\n",
    "\n",
    "decoder_model = Model([decoder_input_inf]+decoder_state_input,[decoder_output_final]+decoder_state_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        \n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        \n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(a):\n",
    "    \n",
    "    a=a.lower()\n",
    "    l=np.zeros((1,max_length_src),dtype='float32')\n",
    "    \n",
    "    a=a.rstrip().split()\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        l[0][i]=input_token_index[a[i]]\n",
    "    return (decode_sequence(l)[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak anything: \n",
      "I love you\n",
      " मला प्रेम आहे हे \n"
     ]
    }
   ],
   "source": [
    "r=sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"speak anything: \")\n",
    "    audio=r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(text)\n",
    "        print(prediction(text))\n",
    "        tts=gTTS(text=prediction(text),lang='hi',slow=False)\n",
    "        tts.save('conv.mp3')\n",
    "        os.system('conv.mp3')\n",
    "        \n",
    "    except:\n",
    "        tts=gTTS(text=\"could not recognize the input\",lang='en',slow=False)\n",
    "        tts.save('conv1.mp3')\n",
    "        os.system('conv1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
