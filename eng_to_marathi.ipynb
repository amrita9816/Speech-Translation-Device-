{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import model_from_json,load_model,Model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38696, 2)\n"
     ]
    }
   ],
   "source": [
    "lines=pd.read_table('eng-mar-dataset.txt',names=['eng', 'mar','waste'])\n",
    "del lines['waste']\n",
    "print(lines.shape)\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.mar=lines.mar.apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.mar=lines.mar.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.mar = lines.mar.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.mar=lines.mar.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar=lines.mar.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.mar = lines.mar.apply(lambda x : 'START_ '+ x + ' _END')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>i dont like the taste of tomatoes</td>\n",
       "      <td>START_ मला टोमॅटोची चव आवडत नाही _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18463</th>\n",
       "      <td>greece has many islands</td>\n",
       "      <td>START_ ग्रीसमध्ये अनेक बेटं आहेत _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>its monkey meat</td>\n",
       "      <td>START_ ते माकडाचं मांस आहे _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22508</th>\n",
       "      <td>my coffee mug disappeared</td>\n",
       "      <td>START_ माझा कॉफी मग गायब झाला _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29837</th>\n",
       "      <td>why do you want to leave today</td>\n",
       "      <td>START_ तुला आज का निघायचं आहे _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38676</th>\n",
       "      <td>our website is offline for scheduled maintenan...</td>\n",
       "      <td>START_ आमचे संकेतस्थळ नियोजित देखरेखीकरिता ऑफल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7602</th>\n",
       "      <td>she is aggressive</td>\n",
       "      <td>START_ ती आक्रमक आहे _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31347</th>\n",
       "      <td>tom said that he liked the movie</td>\n",
       "      <td>START_ टॉम म्हणाला की त्याला चित्रपट आवडला _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30164</th>\n",
       "      <td>i have watched all of her films</td>\n",
       "      <td>START_ मी त्यांचे सगळे चित्रपट पाहिले आहेत _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17679</th>\n",
       "      <td>tom already knows this</td>\n",
       "      <td>START_ टॉमला हे आधीच माहीत आहे _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     eng  \\\n",
       "32532                  i dont like the taste of tomatoes   \n",
       "18463                            greece has many islands   \n",
       "5889                                     its monkey meat   \n",
       "22508                          my coffee mug disappeared   \n",
       "29837                     why do you want to leave today   \n",
       "38676  our website is offline for scheduled maintenan...   \n",
       "7602                                   she is aggressive   \n",
       "31347                   tom said that he liked the movie   \n",
       "30164                    i have watched all of her films   \n",
       "17679                             tom already knows this   \n",
       "\n",
       "                                                     mar  \n",
       "32532              START_ मला टोमॅटोची चव आवडत नाही _END  \n",
       "18463              START_ ग्रीसमध्ये अनेक बेटं आहेत _END  \n",
       "5889                     START_ ते माकडाचं मांस आहे _END  \n",
       "22508                 START_ माझा कॉफी मग गायब झाला _END  \n",
       "29837                 START_ तुला आज का निघायचं आहे _END  \n",
       "38676  START_ आमचे संकेतस्थळ नियोजित देखरेखीकरिता ऑफल...  \n",
       "7602                           START_ ती आक्रमक आहे _END  \n",
       "31347    START_ टॉम म्हणाला की त्याला चित्रपट आवडला _END  \n",
       "30164    START_ मी त्यांचे सगळे चित्रपट पाहिले आहेत _END  \n",
       "17679                START_ टॉमला हे आधीच माहीत आहे _END  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5585, 13386)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "\n",
    "all_marathi_words=set()\n",
    "for mar in lines.mar:\n",
    "    for word in mar.split():\n",
    "        if word not in all_marathi_words:\n",
    "            all_marathi_words.add(word)\n",
    "            \n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "max_length_src\n",
    "\n",
    "lenght_list=[]\n",
    "for l in lines.mar:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "max_length_tar\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_marathi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_marathi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13387"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model_2.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json)\n",
    "\n",
    "model_loaded.load_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "\n",
    "encoder_inputs_inf = model_loaded.input[0] \n",
    "encoder_outputs_inf, inf_state_h, inf_state_c = model_loaded.layers[4].output\n",
    "encoder_inf_states = [inf_state_h,inf_state_c]\n",
    "encoder_model = Model(encoder_inputs_inf,encoder_inf_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_h_input = Input(shape=(latent_dim,)) \n",
    "decoder_state_c_input = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_h_input,decoder_state_c_input]\n",
    "\n",
    "\n",
    "decoder_input_inf = model_loaded.input[1] \n",
    "\n",
    "decoder_emb_inf = model_loaded.layers[3](decoder_input_inf)\n",
    "decoder_lstm_inf = model_loaded.layers[5]\n",
    "decoder_output_inf, decoder_state_h_inf, decoder_state_c_inf = decoder_lstm_inf(decoder_emb_inf, initial_state =decoder_state_input)\n",
    "decoder_state_inf = [decoder_state_h_inf,decoder_state_c_inf]\n",
    "\n",
    "dense_inf = model_loaded.layers[6]\n",
    "decoder_output_final = dense_inf(decoder_output_inf)\n",
    "\n",
    "decoder_model = Model([decoder_input_inf]+decoder_state_input,[decoder_output_final]+decoder_state_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        \n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        \n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(a):\n",
    "    \n",
    "    a=a.lower()\n",
    "    l=np.zeros((1,max_length_src),dtype='float32')\n",
    "    \n",
    "    a=a.rstrip().split()\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        l[0][i]=input_token_index[a[i]]\n",
    "    return (decode_sequence(l)[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak anything: \n"
     ]
    }
   ],
   "source": [
    "r=sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"speak anything: \")\n",
    "    audio=r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(text)\n",
    "        print(prediction(text))\n",
    "        tts=gTTS(text=prediction(text),lang='hi',slow=False)\n",
    "        tts.save('conv.mp3')\n",
    "        os.system('conv.mp3')\n",
    "        \n",
    "    except:\n",
    "        tts=gTTS(text=\"could not recognize the input\",lang='en',slow=False)\n",
    "        tts.save('conv1.mp3')\n",
    "        os.system('conv1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
